# Local RAG Assistant ğŸ¤–

A powerful, local-first Retrieval-Augmented Generation (RAG) system using OpenSearch for vector storage and LM Studio for local LLM inference.

## ğŸ—ï¸ Architecture

![Architecture](assets/architecture_diagram.jpg)

The system follows a standard RAG pipeline:

1. **Ingestion**: PDFs are loaded, chunked using `RecursiveCharacterTextSplitter`, and embedded using `all-MiniLM-L6-v2`.
2. **Storage**: Chunks and embeddings are stored in an OpenSearch k-NN index.
3. **Retrieval**: User queries are embedded and used to find the most relevant chunks in OpenSearch.
4. **Generation**: The retrieved context is injected into a system prompt and sent to a local LLM via an OpenAI-compatible API.

## ğŸ“‚ Project Structure

```text
RAG_T/
â”œâ”€â”€ app.py                # Main Streamlit Application
â”œâ”€â”€ src/                  # Core modules
â”‚   â”œâ”€â”€ embeddings.py     # Embedding logic
â”‚   â”œâ”€â”€ ingestion.py      # PDF processing and indexing
â”‚   â”œâ”€â”€ llm_client.py     # LLM interaction utility
â”‚   â”œâ”€â”€ rag_engine.py      # RAG orchestrator
â”‚   â””â”€â”€ vector_store.py   # OpenSearch interactions
â”œâ”€â”€ prompts/              # System prompt templates
â”œâ”€â”€ tests/                # Automated/Manual test scripts
â”œâ”€â”€ scripts/              # Diagnostic and maintenance tools
â””â”€â”€ assets/               # Documentation assets
```

## ğŸš€ Getting Started

### Prerequisites

- **OpenSearch**: Running locally on port 9200.
- **LM Studio**: Or any OpenAI-compatible server running on port 1234.
- **Python 3.9+**

### Installation

1. Clone the repository and navigate to the project directory.
2. Install dependencies:

   ```bash
   pip install streamlit openai opensearch-py sentence-transformers pymupdf langchain-text-splitters
   ```

### Running the App

```bash
streamlit run app.py
```

### Ingestion

You can upload and index PDFs directly through the Streamlit UI sidebar.

## ğŸ› ï¸ Development & Diagnostics

- **Run Tests**: `python tests/test_rag_engine.py`
- **Check Mapping**: `python scripts/diag_opensearch.py`
- **Reset Indices**: `python scripts/reset_os_indices.py`

## ğŸ“Š Performance Tracking

The system tracks search latency and LLM token usage for every query, providing transparency into the RAG process.
